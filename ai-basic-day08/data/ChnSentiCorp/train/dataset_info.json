grad_norm": 4.482626438140869,
      "learning_rate": 3.897982258676867e-05,
      "loss": 0.3278,
      "step": 560
    },
    {
      "epoch": 4.6887966804979255,
      "grad_norm": 3.268362283706665,
      "learning_rate": 3.879842463280145e-05,
      "loss": 0.3579,
      "step": 565
    },
    {
      "epoch": 4.730290456431535,
      "grad_norm": 3.791735887527466,
      "learning_rate": 3.861597587537568e-05,
      "loss": 0.3899,
      "step": 570
    },
    {
      "epoch": 4.771784232365145,
      "grad_norm": 4.149934768676758,
      "learning_rate": 3.84324902086706e-05,
      "loss": 0.3354,
      "step": 575
    },
    {
      "epoch": 4.813278008298755,
      "grad_norm": 6.095921039581299,
      "learning_rate": 3.824798160583012e-05,
      "loss": 0.3968,
      "step": 580
    },
    {
      "epoch": 4.854771784232365,
      "grad_norm": 4.0573625564575195,
      "learning_rate": 3.8062464117898724e-05,
      "loss": 0.4696,
      "step": 585
    },
    {
      "epoch": 4.8962655601659755,
      "grad_norm": 1.4379432201385498,
      "learning_rate": 3.787595187275136e-05,
      "loss": 0.2436,
      "step": 590
    },
    {
      "epoch": 4.937759336099585,
      "grad_norm": 4.995328426361084,
      "learning_rate": 3.7688459074017606e-05,
      "loss": 0.494,
      "step": 595
    },
    {
      "epoch": 4.979253112033195,
      "grad_norm": 2.305262804031372,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.3025,
      "step": 600
    },
    {
      "epoch": 4.979253112033195,
      "eval_loss": 1.4660485982894897,
      "eval_runtime": 1.1158,
      "eval_samples_per_second": 8.962,
      "eval_steps_per_second": 4.481,
      "step": 600
    },
    {
      "epoch": 5.020746887966805,
      "grad_norm": 4.898987293243408,
      "learning_rate": 3.731058900258668e-05,