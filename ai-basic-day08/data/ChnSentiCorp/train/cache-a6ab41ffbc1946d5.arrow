": 4.817959636416969e-05,
      "loss": 0.9162,
      "step": 220
    },
    {
      "epoch": 1.8672199170124482,
      "grad_norm": 1.9800877571105957,
      "learning_rate": 4.8096988312782174e-05,
      "loss": 0.5358,
      "step": 225
    },
    {
      "epoch": 1.908713692946058,
      "grad_norm": 3.1742615699768066,
      "learning_rate": 4.8012621336311016e-05,
      "loss": 0.9004,
      "step": 230
    },
    {
      "epoch": 1.950207468879668,
      "grad_norm": 3.3186261653900146,
      "learning_rate": 4.79265018596281e-05,
      "loss": 0.8474,
      "step": 235
    },
    {
      "epoch": 1.991701244813278,
      "grad_norm": 3.724370241165161,
      "learning_rate": 4.783863644106502e-05,
      "loss": 0.7711,
      "step": 240
    },
    {
      "epoch": 2.033195020746888,
      "grad_norm": 1.9238078594207764,
      "learning_rate": 4.7749031771913584e-05,
      "loss": 0.701,
      "step": 245
    },
    {
      "epoch": 2.074688796680498,
      "grad_norm": 1.8097978830337524,
      "learning_rate": 4.765769467591625e-05,
      "loss": 0.6366,
      "step": 250
    },
    {
      "epoch": 2.116182572614108,
      "grad_norm": 1.8248306512832642,
      "learning_rate": 4.756463210874652e-05,
      "loss": 0.7733,
      "step": 255
    },
    {
      "epoch": 2.1576763485477177,
      "grad_norm": 2.4334611892700195,
      "learning_rate": 4.7469851157479177e-05,
      "loss": 0.8576,
      "step": 260
    },
    {
      "epoch": 2.199170124481328,
      "grad_norm": 2.044924259185791,
      "learning_rate": 4.737335904005063e-05,
      "loss": 0.6165,
      "step": 265
    },
    {
      "epoch": 2.240663900414938,
      "grad_norm": 2.4657227993011475,
      "learning_rate": 4.72751631047092e-05,
      "loss": 0.2415,
      "step": 270
    },
    {
      "epoch": 2.2821576763485476,
      "grad_norm": 3.308854579925537,
      "learning_rate": 4.717527082945554e-05,
      "loss": 0.7105,
      "step": 275
    },
    {
      "epoch": 2.323651452282158,
      "grad_norm": 1.8085354566574097,
      "learning_rate": 4.707368982147318e-05,
      "loss": 0.447,
      "step": 280
    },
    {
      "epoch": 2.3651452282157677,
      "grad_norm": 2.6618309020996094,
      "learning_rate": 4.697042781654913e-05,
      "loss": 0.6295,
      "step": 285
    },
    {
      "epoch": 2.4066390041493775,
      "grad_norm": 3.632760763168335,
      "learning_rate": 4.6865492678484895e-05,
      "loss": 0.8155,
      "step": 290
    },
    {
      "epoch": 2.4481327800829877,
      "grad_norm": 1.9543602466583252,
      "learning_rate": 4.6758892398497494e-05,
      "loss": 0.6573,
      "step": 295
    },
    {
      "epoch": 2.4896265560165975,
      "grad_norm": 1.8794361352920532,
      "learning_rate": 4.665063509461097e-05,
      "loss": 0.5451,
      "step": 300
    },
    {
      "epoch": 2.4896265560165975,
      "eval_loss": 1.2669506072998047,
      "eval_runtime": 1.1163,
      "eval_samples_per_second": 8.958,
      "eval_steps_per_second": 4.479,
      "step": 300
    },
    {
      "epoch": 2.5311203319502074,
      "grad_norm": 2.701777219772339,
      "learning_rate": 4.6540729011038146e-05,
      "loss": 0.7255,
      "step": 305
    },
    {
      "epoch": 2.572614107883817,
      "grad_norm": 5.90807580947876,
      "learning_rate": 4.642918251755281e-05,
      "loss": 0.6398,
      "step": 310
    },
    {
      "epoch": 2.6141078838174274,
      "grad_norm": 2.3383679389953613,
      "learning_rate": 4.6316004108852305e-05,
      "loss": 0.6866,
      "step": 315
    },
    {
      "epoch": 2.6556016597510372,
      "grad_norm": 3.1714985370635986,
      "learning_rate": 4.620120240391065e-05,
      "loss": 0.5078,
      "step": 320
    },
    {
      "epoch": 2.6970954356846475,
      "grad_norm": 2.4953296184539795,
      "learning_rate": 4.608478614532215e-05,
      "loss": 0.8721,
      "step": 325
    },
    {
      "epoch": 2.7385892116182573,
      "grad_norm": 3.130711317062378,
      "learning_rate": 4.5966764198635606e-05,
      "loss": 0.5548,
      "step": 330
    },
    {
      "epoch": 2.780082987551867,
      "grad_norm": 2.487846851348877,
      "learning_rate": 4.5847145551679206e-05,
      "loss": 0.7413,
      "step": 335
    },
    {
      "epoch": 2.821576763485477,
      "grad_norm": 2.892336845397949,
      "learning_rate": 4.572593931387604e-05,
      "loss": 0.6211,
      "step": 340
    },
    {
      "epoch": 2.863070539419087,
      "grad_norm": 3.9812328815460205,
      "learning_rate": 4.5603154715550386e-05,
      "loss": 0.6544,
      "step": 345
    },
    {
      "epoch": 2.904564315352697,
      "grad_norm": 3.8013479709625244,
      "learning_rate": 4.54788011072248e-05,
      "loss": 0.6298,
      "step": 350
    },
    {
      "epoch": 2.9460580912863072,
      "grad_norm": 2.6709723472595215,
      "learning_rate": 4.535288795890798e-05,
      "loss": 0.8226,
      "step": 355
    },
    {
      "epoch": 2.987551867219917,
      "grad_norm": 3.418281316757202,
      "learning_rate": 4.522542485937369e-05,
      "loss": 0.7904,
      "step": 360
    },
    {
      "epoch": 3.029045643153527,
      "grad_norm": 3.007279396057129,
      "learning_rate": 4.509642151543043e-05,
      "loss": 0.613,
      "step": 365
    },
    {
      "epoch": 3.070539419087137,
      "grad_norm": 2.539443254470825,
      "learning_rate": 4.496588775118232e-05,
      "loss": 0.632,
      "step": 370
    },
    {
      "epoch": 3.112033195020747,
      "grad_norm": 1.2412099838256836,
      "learning_rate": 4.4833833507280884e-05,
      "loss": 0.4722,
      "step": 375
    },
    {
      "epoch": 3.1535269709543567,
      "grad_norm": 2.120359182357788,
      "learning_rate": 4.4700268840168045e-05,
      "loss": 0.365,
      "step": 380
    },
    {
      "epoch": 3.195020746887967,
      "grad_norm": 2.4853835105895996,
      "learning_rate": 4.456520392131035e-05,
      "loss": 0.4459,
      "step": 385
    },
    {
      "epoch": 3.236514522821577,
      "grad_norm": 3.3844518661499023,
      "learning_rate": 4.442864903642428e-05,
      "loss": 0.3469,
      "step": 390
    },
    {
      "epoch": 3.2780082987551866,
      "grad_norm": 6.140565395355225,
      "learning_rate": 4.4290614584693004e-05,
      "loss": 0.711,
      "step": 395
    },
    {
      "epoch": 3.3195020746887964,
      "grad_norm": 2.216933488845825,
      "learning_rate": 4.415111107797445e-05,
      "loss": 0.2889,
      "step": 400
    },
    {
      "epoch": 3.3195020746887964,
      "eval_loss": 1.3692562580108643,
      "eval_runtime": 1.118,
      "eval_samples_per_second": 8.945,
      "eval_steps_per_second": 4.472,
      "step": 400
    },
    {
      "epoch": 3.3609958506224067,
      "grad_norm": 3.066760540008545,
      "learning_rate": 4.401014914000078e-05,
      "loss": 0.582,
      "step": 405
    },
    {
      "epoch": 3.4024896265560165,
      "grad_norm": 1.6588046550750732,
      "learning_rate": 4.386773950556931e-05,
      "loss": 0.4344,
      "step": 410
    },
    {
      "epoch": 3.4439834024896268,
      "grad_norm": 2.7112104892730713,
      "learning_rate": 4.372389301972506e-05,
      "loss": 0.4904,
      "step": 415
    },
    {
      "epoch": 3.4854771784232366,
      "grad_norm": 4.418873310089111,
      "learning_rate": 4.357862063693486e-05,
      "loss": 0.5784,
      "step": 420
    },
    {
      "epoch": 3.5269709543568464,
      "grad_norm": 3.228391647338867,
      "learning_rate": 4.34319334202531e-05,
      "loss": 0.4964,
      "step": 425
    },
    {
      "epoch": 3.568464730290456,
      "grad_norm": 3.4239606857299805,
      "learning_rate": 4.3283842540479264e-05,
      "loss": 0.6262,
      "step": 430
    },
    {
      "epoch": 3.6099585062240664,
      "grad_norm": 4.406198024749756,
      "learning_rate": 4.313435927530719e-05,
      "loss": 0.5543,
      "step": 435
    },
    {
      "epoch": 3.6514522821576763,
      "grad_norm": 3.0809459686279297,
      "learning_rate": 4.2983495008466276e-05,
      "loss": 0.4517,
      "step": 440
    },
    {
      "epoch": 3.6929460580912865,
      "grad_norm": 4.45768785