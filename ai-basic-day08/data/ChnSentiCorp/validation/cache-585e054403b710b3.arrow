 1.1384024124624324e-05,
      "loss": 0.0134,
      "step": 1230
    },
    {
      "epoch": 10.248962655601659,
      "grad_norm": 0.8777076601982117,
      "learning_rate": 1.1201575367198547e-05,
      "loss": 0.018,
      "step": 1235
    },
    {
      "epoch": 10.29045643153527,
      "grad_norm": 2.0701987743377686,
      "learning_rate": 1.1020177413231334e-05,
      "loss": 0.0368,
      "step": 1240
    },
    {
      "epoch": 10.33195020746888,
      "grad_norm": 1.2319525480270386,
      "learning_rate": 1.0839844076879185e-05,
      "loss": 0.0154,
      "step": 1245
    },
    {
      "epoch": 10.37344398340249,
      "grad_norm": 1.0581389665603638,
      "learning_rate": 1.0660589091223855e-05,
      "loss": 0.0148,
      "step": 1250
    },
    {
      "epoch": 10.4149377593361,
      "grad_norm": 1.5669938325881958,
      "learning_rate": 1.0482426107226507e-05,
      "loss": 0.03,
      "step": 1255
    },
    {
      "epoch": 10.45643153526971,
      "grad_norm": 1.2019537687301636,
      "learning_rate": 1.0305368692688174e-05,
      "loss": 0.028,
      "step": 1260
    },
    {
      "epoch": 10.49792531120332,
      "grad_norm": 0.3951317071914673,
      "learning_rate": 1.0129430331216471e-05,
      "loss": 0.0136,
      "step": 1265
    },
    {
      "epoch": 10.53941908713693,
      "grad_norm": 0.9818621873855591,
      "learning_rate": 9.954624421198792e-06,
      "loss": 0.0177,
      "step": 1270
    },
    {
      "epoch": 10.58091286307054,
      "grad_norm": 3.8411808013916016,
      "learning_rate": 9.780964274781984e-06,
      "loss": 0.0368,
      "step": 1275
    },
    {
      "epoch": 10.622406639004149,
      "grad_norm": 1.2754203081130981,
      "learning_rate": 9.608463116858542e-06,
      "loss": 0.0206,
      "step": 1280
    },
    {
      "epoch": 10.663900414937759,
      "grad_norm": 0.6347295045852661,
      "learning_rate": 9.437134084059515e-06,
      "loss": 0.0235,
      "step": 1285
    },
    {
      "epoch": 10.705394190871369,
      "grad_norm": 1.1475993394851685,
      "learning_rate": 9.266990223754069e-06,
      "loss": 0.0244,
      "step": 1290
    },
    {
      "epoch": 10.74688796680498,
      "grad_norm": 1.4736459255218506,
      "learning_rate": 9.098044493055899e-06,
      "loss": 0.0561,
      "step": 1295
    },
    {
      "epoch": 10.78838174273859,
      "grad_norm": 1.450006365776062,
      "learning_rate": 8.930309757836517e-06,
      "loss": 0.0387,
      "step": 1300
    },
    {
      "epoch": 10.78838174273859,
      "eval_loss": 2.2582650184631348,
      "eval_runtime": 1.1169,
      "eval_samples_per_second": 8.953,
      "eval_steps_per_second": 4.477,
      "step": 1300
    },
    {
      "epoch": 10.8298755186722,
      "grad_norm": 0.4344078004360199,
      "learning_rate": 8.763798791745411e-06,
      "loss": 0.0217,
      "step": 1305
    },
    {
      "epoch": 10.87136929460581,
      "grad_norm": 0.9884241819381714,
      "learning_rate": 8.598524275237322e-06,
      "loss": 0.0386,
      "step": 1310
    },
    {
      "epoch": 10.91286307053942,
      "grad_norm": 1.5018337965011597,
      "learning_rate": 8.434498794606568e-06,
      "loss": 0.0242,
      "step": 1315
    },
    {
      "epoch": 10.95435684647303,
      "grad_norm": 0.7100182771682739,
      "learning_rate": 8.271734841028553e-06,
      "loss": 0.0307,
      "step": 1320
    },
    {
      "epoch": 10.995850622406639,
      "grad_norm": 3.3627896308898926,
      "learning_rate": 8.110244809608495e-06,
      "loss": 0.017,
      "step": 1325
    },
    {
      "epoch": 11.037344398340249,
      "grad_norm": 0.46316081285476685,
      "learning_rate": 7.950040998437542e-06,
      "loss": 0.0096,
      "step": 1330
    },
    {
      "epoch": 11.078838174273859,
      "grad_norm": 1.0034620761871338,
      "learning_rate": 7.791135607656147e-06,
      "loss": 0.0159,
      "step": 1335
    },
    {
      "epoch": 11.120331950207468,
      "grad_norm": 0.40875905752182007,
      "learning_rate": 7.633540738525066e-06,
      "loss": 0.0086,
      "step": 1340
    },
    {
      "epoch": 11.161825726141078,
      "grad_norm": 4.591676235198975,
      "learning_rate": 7.477268392503728e-06,
      "loss": 0.0154,
      "step": 1345
    },
    {
      "epoch": 11.203319502074688,
      "grad_norm": 1.0189939737319946,
      "learning_rate": 7.3223304703363135e-06,
      "loss": 0.0105,
      "step": 1350
    },
    {
      "epoch": 11.244813278008298,
      "grad_norm": 0.938956618309021,
      "learning_rate": 7.168738771145464e-06,
      "loss": 0.0235,
      "step": 1355
    },
    {
      "epoch": 11.28630705394191,
      "grad_norm": 0.9425352215766907,
      "learning_rate": 7.016504991533726e-06,
      "loss": 0.0165,
      "step": 1360
    },
    {
      "epoch": 11.32780082987552,
      "grad_norm": 0.10208716988563538,
      "learning_rate": 6.865640724692815e-06,
      "loss": 0.0071,
      "step": 1365
    },
    {
      "epoch": 11.369294605809129,
      "grad_norm": 0.45511698722839355,
      "learning_rate": 6.716157459520739e-06,
      "loss": 0.0179,
      "step": 1370
    },
    {
      "epoch": 11.410788381742739,
      "grad_norm": 2.0564775466918945,
      "learning_rate": 6.568066579746901e-06,
      "loss": 0.0218,
      "step": 1375
    },
    {
      "epoch": 11.452282157676349,
      "grad_norm": 0.6920590400695801,
      "learning_rate": 6.421379363065142e-06,
      "loss": 0.0338,
      "step": 1380
    },
    {
      "epoch": 11.493775933609959,
      "grad_norm": 0.46802544593811035,
      "learning_rate": 6.2761069802749455e-06,
      "loss": 0.0093,
      "step": 1385
    },
    {
      "epoch": 11.535269709543568,
      "grad_norm": 0.05851922556757927,
      "learning_rate": 6.1322604944307e-06,
      "loss": 0.008,
      "step": 1390
    },
    {
      "epoch": 11.576763485477178,
      "grad_norm": 0.48695212602615356,
      "learning_rate": 5.989850859999227e-06,
      "loss": 0.0113,
      "step": 1395
    },
    {
      "epoch": 11.618257261410788,
      "grad_norm": 0.7955949902534485,
      "learning_rate": 5.848888922025553e-06,
      "loss": 0.0341,
      "step": 1400
    },
    {
      "epoch": 11.618257261410788,
      "eval_loss": 2.3975257873535156,
      "eval_runtime": 1.1169,
      "eval_samples_per_second": 8.954,
      "eval_steps_per_second": 4.477,
      "step": 1400
    },
    {
      "epoch": 11.659751037344398,
      "grad_norm": 1.447558879852295,
      "learning_rate": 5.709385415307006e-06,
      "loss": 0.017,
      "step": 1405
    },
    {
      "epoch": 11.701244813278008,
      "grad_norm": 0.30031776428222656,
      "learning_rate": 5.571350963575728e-06,
      "loss": 0.0094,
      "step": 1410
    },
    {
      "epoch": 11.74273858921162,
      "grad_norm": 2.41595458984375,
      "learning_rate": 5.434796078689652e-06,
      "loss": 0.0318,
      "step": 1415
    },
    {
      "epoch": 11.784232365145229,
      "grad_norm": 1.1240999698638916,
      "learning_rate": 5.299731159831953e-06,
      "loss": 0.0126,
      "step": 1420
    },
    {
      "epoch": 11.825726141078839,
      "grad_norm": 0.5484392046928406,
      "learning_rate": 5.166166492719124e-06,
      "loss": 0.0227,
      "step": 1425
    },
    {
      "epoch": 11.867219917012449,
      "grad_norm": 1.0259578227996826,
      "learning_rate": 5.034112248817685e-06,
      "loss": 0.0109,
      "step": 1430
    },
    {
      "epoch": 11.908713692946058,
      "grad_norm": 0.29543280601501465,
      "learning_rate": 4.903578484569568e-06,
      "loss": 0.0147,
      "step": 1435
    },
    {
      "epoch": 11.950207468879668,
      "grad_norm": 0.14626817405223846,
      "learning_rate": 4.7745751406263165e-06,
      "loss": 0.0179,
      "step": 1440
    },
    {
      "epoch": 11.991701244813278,
      "grad_norm": 0.9792938232421875,
      "learning_rate": 4.647112041092022e-06,
      "loss": 0.0191,
      "step": 1445
    },
    {
      "epoch": 12.033195020746888,
      "grad_norm": 0.4541969299316406,
      "learning_rate": 4.521198892775203e-06,
      "loss": 0.0224,
      "step": 1450
    },
    {
      "epoch": 12.074688796680498,
      "grad_norm": 0.5591984391212463,
      "learning_rate": 4.396845284449608e-06,
      "loss": 0.0153,
      "step": 1455
    },
    {
      "epoch": 12.116182572614107,
      "grad_norm": 0.36519017815589905,
      "learning_rate": 4.274060686123959e-06,
      "loss": 0.0085,
      "step": 1460
    },
    {
      "epoch": 12.157676348547717,
      "grad_norm": 0.24349772930145264,
      "learning_rate": 4.152854448320797e-06,
      "loss": 0.0097,
      "step": 1465
    },
    {
      "epoch": 12.199170124481327,
      "grad_norm": 0.54826420545578,
      "learning_rate": 4.0332358013644016e-06,
      "loss": 0.0071,
      "step": 1470
    },
    {
      "epoch": 12.240663900414937,
      "grad_norm": 1.6832318305969238,
      "learning_rate": 3.9152138546778625e-06,
      "loss": 0.0197,
      "step": 1475
    },
    {
      "epoch": 12.282157676348548,
      "grad_norm": 0.4451075494289398,
      "learning_rate": 3.798797596089351e-06,
      "loss": 0.0094,
      "step": 1480
    },
    {
      "epoch": 12.323651452282158,
      "grad_norm": 0.4112599790096283,
      "learning_rate": 3.6839958911476957e-06,
      "loss": 0.0076,
      "step": 1485
    },
    {
      "epoch": 12.365145228215768,
      "grad_norm": 0.28678610920906067,
      "learning_rate": 3.5708174824471947e-06,
      "loss": 0.0092,
      "step": 1490
    },
    {
      "epoch": 12.406639004149378,
      "grad_norm": 0.2839852571487427,
      "learning_rate": 3.4592709889618545e-06,
      "loss": 0.0079,
      "step": 1495
    },
    {
      "epoch": 12.448132780082988,
      "grad_norm": 0.38442283868789673,
     